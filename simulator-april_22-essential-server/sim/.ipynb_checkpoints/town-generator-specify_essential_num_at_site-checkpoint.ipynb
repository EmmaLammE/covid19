{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generates Mobility file for inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import copy\n",
    "import scipy as sp\n",
    "import math\n",
    "import seaborn\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from lib.mobilitysim import MobilitySimulator\n",
    "from lib.town_data import generate_population, generate_sites, compute_distances\n",
    "from lib.town_maps import MapIllustrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for synthetic mobility data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_population = 100 # Downsample population numbers by a factor of 20\n",
    "downsample_sites = 20 # Downsample sites by a factor of 10\n",
    "\n",
    "# Set the population generation mode.\n",
    "# 3 options available: custom | random | heuristic\n",
    "population_by = 'custom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Town details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population per age group: [53, 73, 268, 299, 165, 47]\n"
     ]
    }
   ],
   "source": [
    "population_path='lib/data/population/' # Directory containing FB population density files\n",
    "sites_path='lib/data/queries/' # Directory containing OSM site files\n",
    "bbox = (48.4900, 48.5485, 9.0224, 9.1061) # Coordinate bounding box\n",
    "\n",
    "# Population per age group in Landkreis Tübingen\n",
    "population_per_age_group = np.array([\n",
    "    13416, # 0-4\n",
    "    18324, # 5-14\n",
    "    67389, # 15-34\n",
    "    75011, # 35-59\n",
    "    41441, # 60-79\n",
    "    11750])# 80+\n",
    "\n",
    "# Downsample population to Town of Tübingen (to be consistent with case data)\n",
    "a = 90546 / (downsample_population * 227331)\n",
    "population_per_age_group = np.round(\n",
    "    population_per_age_group * a).astype('int').tolist()\n",
    "\n",
    "print(f'Population per age group: {population_per_age_group}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 905\n",
      "essen: [0, 0, 22, 20, 2, 0]\n",
      "age g: [53, 73, 268, 299, 165, 47]\n",
      "[0.         0.         0.08208955 0.06688963 0.01212121 0.        ] 0.1611003964670415\n",
      "[ 0.          0.         74.29104478 60.53511706 10.96969697  0.        ]\n"
     ]
    }
   ],
   "source": [
    "essential_to_total_ratio = 0.05\n",
    "num_essential_workers = np.floor(sum(population_per_age_group)*essential_to_total_ratio).astype('int').tolist()\n",
    "print(num_essential_workers,sum(population_per_age_group))\n",
    "\n",
    "essential_type = 4 # supermarket worker\n",
    "\n",
    "essential_distribution = np.array([\n",
    "    0,      # 0-4\n",
    "    0,      # 5-14\n",
    "    0.5,    # 15-34\n",
    "    0.45,   # 34-59\n",
    "    0.05,   # 60-79\n",
    "    0])     # 80+\n",
    "\n",
    "num_essential_per_age_group = np.floor(num_essential_workers * essential_distribution).astype('int').tolist()\n",
    "essential_prop_per_age_group = np.divide((num_essential_per_age_group),(population_per_age_group))\n",
    "\n",
    "print('essen:',(num_essential_per_age_group))\n",
    "print('age g:',population_per_age_group)\n",
    "print(essential_prop_per_age_group,sum(essential_prop_per_age_group))\n",
    "print(essential_prop_per_age_group*sum(population_per_age_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracted site data\n",
    "\n",
    "* site_loc: list of site coordinates\n",
    "* site_type: list of site category\n",
    "* site_dict: helper dictionary with real name (string) of each site category (int)\n",
    "* density_site_loc: list of site coordinates of specific type to be based on to generate population density\n",
    "\n",
    "To generate sites of arbitrary sites for a given city, the following function sends queries to OpenStreetMap. In order to use it for additional types of sites, you need to specify queries in the Overpass API format. For more information, check the existing queries in **/lib/data/queries/**, https://wiki.openstreetmap.org/wiki/Overpass_API and http://overpass-turbo.eu/.\n",
    "\n",
    "We separatelly use a query returning all buildings in a town to heuristically generate population density in the next steps if no real population density data is provided. An extra query is required for this purpose and it should be given as a **site_based_density_file** argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# This block sends queries to OpenStreetMap\n",
    "# Make sure you have a working internet connection\n",
    "# If an error occurs during execution, try executing again\n",
    "site_files=[]\n",
    "for root,dirs,files in os.walk(sites_path):\n",
    "    for f in files:\n",
    "        if f.endswith(\".txt\") and f != 'buildings.txt':\n",
    "            site_files.append(sites_path+f)\n",
    "\n",
    "site_loc, site_type, site_dict, density_site_loc = generate_sites(bbox=bbox, query_files=site_files,\n",
    "                                site_based_density_file='lib/data/queries/buildings.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate home location based on various options\n",
    "\n",
    "* home_loc: list of home coordinates\n",
    "* people_age: list of age category \n",
    "* home_tile: list of map tile to which each home belongs\n",
    "* tile_loc: list tile center coordinates\n",
    "\n",
    "The following three options generate a population distribution across a geographical area consisting of tiles (square boxes) of specific resolution. More information about tile sizes can be found in https://wiki.openstreetmap.org/wiki/Zoom_levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sites:  48\n",
      "Site types:       {0: 'bus_stop', 1: 'education', 2: 'office', 3: 'social', 4: 'supermarket'}\n",
      "[0, 3, 2, 2, 0, 0, 3, 2, 2, 0, 4, 3, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 3, 0, 1, 2, 0, 2, 0, 0, 3, 4, 3, 0, 2, 1, 0, 1, 0, 3, 0, 2, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "if downsample_sites > 1:\n",
    "    np.random.seed(42)\n",
    "    # downsample sites like populatoin\n",
    "    idx = np.random.choice(len(site_loc), size=int(len(site_loc) / downsample_sites), \n",
    "                           replace=False, p=np.ones(len(site_loc)) / len(site_loc))\n",
    "\n",
    "    new_site_loc, new_site_type = [], []\n",
    "    site_loc, site_type = np.array(site_loc)[idx].tolist(), np.array(site_type)[idx].tolist()\n",
    "    \n",
    "print(f'Number of sites: ', len(site_loc))\n",
    "print(f'Site types:      ', site_dict)\n",
    "print(site_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of essential workers 42\n",
      "total population 905\n",
      "essential/total  0.04640883977900553\n"
     ]
    }
   ],
   "source": [
    "density_files=[]\n",
    "for root,dirs,files in os.walk(population_path):\n",
    "    for f in files:\n",
    "        if f.endswith(\".csv\"):\n",
    "            density_files.append(population_path+f)\n",
    "\n",
    "if population_by == 'custom':\n",
    "    # generate population across tiles based on density input\n",
    "    home_loc, people_age, home_tile, tile_loc, essential_workers, num_essential_workers, essential_work_site = generate_population(density_files=density_files, bbox=bbox,\n",
    "        population_per_age_group=population_per_age_group, tile_level=16, seed=42,\n",
    "        essential_prop_per_age_group=essential_prop_per_age_group,\n",
    "        site_type = site_type, essential_type = essential_type)\n",
    "    \n",
    "elif population_by == 'random':\n",
    "    # generate population across tiles uniformly at random\n",
    "    home_loc, people_age, home_tile, tile_loc, essential_workers, num_essential_workers = generate_population(\n",
    "        bbox=bbox, population_per_age_group=population_per_age_group,\n",
    "        tile_level=16, seed=42,\n",
    "        essential_prop_per_age_group=essential_prop_per_age_group)\n",
    "\n",
    "elif population_by == 'heuristic':\n",
    "    # generate population across tiles proportional to buildings per tile\n",
    "    home_loc, people_age, home_tile, tile_loc, essential_workers, num_essential_workers = generate_population(bbox=bbox, density_site_loc=density_site_loc,\n",
    "                            population_per_age_group=population_per_age_group, tile_level=16, seed=42,\n",
    "        essential_prop_per_age_group=essential_prop_per_age_group)\n",
    "    \n",
    "essential_to_total_pop_ratio = num_essential_workers/sum(population_per_age_group)\n",
    "print('number of essential workers',num_essential_workers)\n",
    "print('total population', sum(population_per_age_group))\n",
    "print('essential/total ', essential_to_total_pop_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample sites as given by settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sites:  48\n",
      "Site types:       {0: 'bus_stop', 1: 'education', 2: 'office', 3: 'social', 4: 'supermarket'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of sites: ', len(site_loc))\n",
    "print(f'Site types:      ', site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute pairwise distances between all tile centers and all sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_site_dist = compute_distances(site_loc, tile_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify synthetic mobility patterns\n",
    "\n",
    "Here we specify the patterns of mobility used for generating the synthetic traces based on the above home and site locations. Note that this is a general framework and can by arbitrarilty extended to any desired site numbers or types. See below for an example used in the first version of our paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the mean duration of visit per type, or in reality, time spent in crowded places per type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2h at office-education, 1.5h at restaurants/bars, 0.5 at supermarket, 0.2 at bus stop.\n",
    "dur_mean_per_type = [2, 1.5, 0.2, 2, 0.5]\n",
    "essential_dur_mean_per_type = [8.0 , 0.0 , 0.0 , 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the number of discrete sites a person visits per site type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 office, 1 school, 10 social, 2 supermarkets, 5 bus stops\n",
    "variety_per_type = [1, 10, 5, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of visits per week that each group makes per type of site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. line 0 corresponds to age 0-4 : \n",
    "# no office, a lot of education (kindergarden), some social, no supermarket, no public transport \n",
    "# school, social, bus, office, supermarket\n",
    "mob_rate_per_age_per_type = [\n",
    "    [5, 1, 0, 0, 0], # 0-4\n",
    "    [5, 2, 1, 0, 0], # 5-14\n",
    "    [2, 2, 1, 1, 1], # 15-34\n",
    "    [0, 2, 1, 5, 1], # 35-59\n",
    "    [0, 3, 2, 0, 1], # 60-79\n",
    "    [0, 2, 1, 0, 1]] # 80+\n",
    "    \n",
    "# convert to average visits per hour per week, to be compatible with simulator\n",
    "mob_rate_per_age_per_type = np.divide(np.array(mob_rate_per_age_per_type), (24.0 * 7))\n",
    "\n",
    "essential_mob_rate_per_type = [7 , 0 , 0 , 0, 0]\n",
    "essential_mob_rate_per_type = np.divide(np.array(essential_mob_rate_per_type), (24.0 * 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set time horizon and delta. Due to the data horizon considered for inference, we use 17 days. The setting for delta is explained in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time horizon\n",
    "max_time = 17 * 24.0 # data availability\n",
    "delta  = 4.6438 # as set by distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save arguments for the class object instantiation to be able to initiate `MobilitySimulator` on the fly during inference. That is more efficient than pickling in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(home_loc=home_loc, people_age=people_age, site_loc=site_loc,\n",
    "    site_type=site_type, mob_rate_per_age_per_type=mob_rate_per_age_per_type,\n",
    "    dur_mean_per_type=dur_mean_per_type, variety_per_type=variety_per_type, delta=delta,\n",
    "    home_tile=home_tile, tile_site_dist=tile_site_dist,\n",
    "    essential_workers=essential_workers,\n",
    "    essential_mob_rate_per_type=essential_mob_rate_per_type,\n",
    "    essential_dur_mean_per_type = essential_dur_mean_per_type,\n",
    "    essential_work_site = essential_work_site) # emma\n",
    "\n",
    "with open(f'essential-prop0_school_settings_{downsample_population}_{downsample_sites}.pk', 'wb') as fp:\n",
    "    pickle.dump(kwargs, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mobility traces as above, or comment in the last section bleow to specify fully artifial traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob = MobilitySimulator(**kwargs)\n",
    "mob.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulate mobility for 408.00 time units... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\softwareinstallation\\python\\lib\\site-packages\\numba\\core\\ir_utils.py:2031: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'essential_workers' of function '_simulate_real_mobility_traces'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"lib\\mobilitysim.py\", line 210:\u001b[0m\n",
      "\u001b[1m@numba.njit\n",
      "\u001b[1mdef _simulate_real_mobility_traces(*, num_people, max_time, site_type, people_age, mob_rate_per_age_per_type,\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 63254 visits.\n",
      "Wall time: 6.14 s/238king site 1/238\n"
     ]
    }
   ],
   "source": [
    "%time mob.simulate(max_time=max_time, seed=12345)\n",
    "# %time mob.to_pickle(f'tu_mobility_{downsample_population}_{downsample_sites}.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total population: 4528 , essential: 42 , non_essential: 4486 , propotion: 0.009275618374558304\n",
      "sites: 238\n",
      "[0.         0.         0.01639344 0.01338688 0.00242424 0.        ] 0.03220456590395362\n",
      "Population (by Age):  [267, 365, 1342, 1494, 825, 234]\n",
      "Sites (by type):      [105, 33, 47, 44, 9]\n",
      "Total: 4527 238\n"
     ]
    }
   ],
   "source": [
    "num_essen = 0\n",
    "num_non_essen = 0\n",
    "for i in range(mob.num_people):\n",
    "    if mob.essential_workers[i]:\n",
    "        num_essen += 1\n",
    "    else:\n",
    "        num_non_essen += 1\n",
    "\n",
    "print('total population:',mob.num_people,', essential:',num_essen,', non_essential:',num_non_essen,', propotion:',num_essen/mob.num_people)\n",
    "print('sites:',len(site_loc))\n",
    "print(essential_prop_per_age_group,sum(essential_prop_per_age_group))\n",
    "\n",
    "print('Population (by Age): ', population_per_age_group)\n",
    "print('Sites (by type):     ',  [(np.array(site_type) == i).sum() for i in range(5)])\n",
    "\n",
    "print('Total:', sum(population_per_age_group), len(site_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
